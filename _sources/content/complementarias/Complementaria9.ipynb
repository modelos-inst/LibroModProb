{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <h3 style=\"color: #ADD8E6;\">Complementaria 9: MDP en Python</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este tutorial nos concentramos en la implementación del modúlo de MDP de `jmarkov` en Python. Este modúlo permite encontrar la política óptima de un proceso de decisión markoviano (MDP) mediante dos posibles metódos de solución, iteración por valor o iteración de política."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #ADD8E6;\">Ejercicio MDP: héroes y villanos</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se abordará el problema 1 del archivo `Complementaria 10 (Q).pdf` que se encuentra en BloqueNeón. Modelaremos la situación como un proceso de decisión markoviano (MDP). Para esto, se deben definir los seis componentes principales del problema: \n",
    "1. Épocas de decisión.\n",
    "2. Variable de estado.\n",
    "3. Espacio de estados.\n",
    "4. Espacio  decisiones.\n",
    "5. Probabilidades de transición,\n",
    "6. Recompensas inmediatas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos las épocas:\n",
    "$\n",
    "E = \\{1,2,..., \\infty \\} \\rightarrow \\text{cada ataque}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la variable de estado como:\n",
    "$\n",
    "X_t = \\text{Lugar donde atacaron los villanos en el t-1-ésimo ataque } t\\\\\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el espacio de estados:\n",
    "$\n",
    "S_X = \\{AC,AS\\}\\\\ \n",
    "$\n",
    "Donde AC significa que atacaron el centro y AS que atacaron los suburbios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El espacio de decisiones:\n",
    "$\n",
    "A(i) = \\{C,S\\}\n",
    "$\n",
    "Donde C indica que los superhéroes se van al centro y S que se van a los suburbios. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Tendremos una matriz de transición para cada decisión.\n",
    "\n",
    "$\n",
    "P_{i \\to j}^{(a = Suburbio)}= \n",
    "\\begin{array}{c|cc}\n",
    "   & \\text{Centro}& \\text{Suburbio}  \\\\\n",
    "    \\hline\n",
    "    \\text{Centro} & 0.5 & 0.5 \\\\\n",
    "    \\text{Suburbio} & 0.6 & 0.4 \n",
    "    \\end{array}\n",
    "\\\\\n",
    "P_{i \\to j}^{(a = Centro)}= \n",
    "\\begin{array}{c|cc}\n",
    "   & \\text{Centro}& \\text{Suburbio}  \\\\\n",
    "    \\hline\n",
    "    \\text{Centro} & 0.3 & 0.7 \\\\\n",
    "    \\text{Suburbio} & 0.8 & 0.2\n",
    "    \\end{array}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, definimos los retornos. Estos corresponden a las batallas ganadas. Notemos que se ganan las batallas cuando los villanos van al lugar que los superhéroes decidieron ir. Así, los retornos son:\n",
    "\n",
    "$\n",
    "r_{(AS,S)} = 0.4\\\\\n",
    "r_{(AS,C)} = 0.8 \\\\\n",
    "r_{(AC,C)} = 0.3 \\\\\n",
    "r_{(AC,S)} = 0.5\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para empezar con la implementación, llamamos las librerías necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from jmarkov.mdp.dtmdp import dtmdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos el espacio de estados en Python como un arreglo de numpy, de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Centro', 'Suburbio'], dtype='<U8')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estadosHeroes = np.array(['Centro','Suburbio'])\n",
    "estadosHeroes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el espacio de acciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ir al Centro', 'Ir al Suburbio'], dtype='<U14')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accionesHeroes = np.array(['Ir al Centro','Ir al Suburbio'])\n",
    "accionesHeroes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos las matrices de transición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ir al Centro': array([[0.5, 0.5],\n",
       "        [0.6, 0.4]]),\n",
       " 'Ir al Suburbio': array([[0.3, 0.7],\n",
       "        [0.8, 0.2]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matricesHeroes = {}\n",
    "\n",
    "for a in accionesHeroes:\n",
    "    if a == 'Ir al Centro':\n",
    "        matricesHeroes[a] = np.array([[0.5,0.5],\n",
    "                                    [0.6,0.4]])\n",
    "    elif a == 'Ir al Suburbio':\n",
    "        matricesHeroes[a] = np.array([[0.3,0.7],\n",
    "                                    [0.8,0.2]])\n",
    "\n",
    "matricesHeroes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos los retornos inmediatos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3, 0.5],\n",
       "       [0.8, 0.4]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retornosHeroes = np.array([[0.3,0.5],\n",
    "                           [0.8,0.4]])\n",
    "retornosHeroes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el problema como un MDP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdpHeroes = dtmdp(estadosHeroes, accionesHeroes, matricesHeroes, retornosHeroes, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, solucionamos.\n",
    "\n",
    "El método `solve` de la librería recibe por parámetro: la tolerancia (GAP) de convergencia y el método de solución, que puede ser iteración por política o iteración por valor. Ambos métodos garantizan encontrar la solución óptima y llegar al mismo valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdpHeroes.solve(0, method='policy_iteration')\n",
    "value_functions, optimal_policy = mdpHeroes.solve(0, method='policy_iteration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que el método `solve` nos devuelve dos resultados. El primero se refiere al valor que toma cada una de las funciones de valor; y el segundo corresponde a la política óptima. En este caso, siempre que se esté en el centro se debe decidir ir al suburbio y siempre que se esté en el suburbio se debe decidir ir al centro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Centro': 'Ir al Suburbio', 'Suburbio': 'Ir al Centro'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valor esperado de la política óptima\n",
    "mdpHeroes.expected_policy_value(value_functions,optimal_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente, la librería nos permite conocer con un comando el valor esperado de la política óptima en el largo plazo y la matriz de probabilidades de transición de la política óptima. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3, 0.7],\n",
       "       [0.6, 0.4]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matriz de transición de la política óptima\n",
    "mdpHeroes.policy_transition_matrix(optimal_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #4CAF50; background-color: #f9f9f9; padding: 10px; border-radius: 5px; font-size: 16px;\">\n",
    "💡 <strong>Reto:</strong> Investiga como funciona la iteración por política y la iteración por valor. ¿En qué se parecen? ¿En qué se diferencian?\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #ADD8E6;\">Ejercicio MDP: estudiantes de la Universidad de Los Alpes</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora intentemos modelar el segundo ejercicio propuesto. ¿Cuáles serían los componentes? ¿Cuántas matrices de probabilidades de transición tendríamos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resuelva el segundo ejercicio propuesto en el archivo `Complementaria 10 (Q).pdf` que se encuentra en BloqueNeón.\n",
    "\n",
    "<details>\n",
    "<summary>Clic aquí para ver la solución</summary>\n",
    "Podemos modelar el problema como un proceso de decisión en el tiempo con épocas infinitas.  \n",
    "Así, el conjunto de las épocas está dado por:\n",
    "\n",
    "$\n",
    "E = \\{1,2,\\dots,\\infty\\} \\rightarrow \\text{cada semestre}\n",
    "$\n",
    "\n",
    "La variable de estados será \n",
    "$\n",
    "X_{t} = \\text{Clasificación de un estudiante en la época } t\n",
    "$\n",
    "Su respectivo espacio de estados:\n",
    "$\n",
    "S_{X} = \\{ Excelente, Bueno, Promedio, Regular\\}\n",
    "$\n",
    "\n",
    "Ya que un estudiante podrá decidir si asistir a clase (1), asistir a clase y realizar complementarias y tareas (2) y asistir a clase, realizar complementarias y tareas y leer el libro guía (3). \n",
    "\n",
    "$\n",
    "A(i) = \n",
    "\\begin{cases}\n",
    "&\\text{Asistir a Clase (1)}, \\\\\n",
    "&\\text{Asistir a Clase y Realizar Complementarias y Tareas (2)}, \\\\\n",
    "&\\text{Asistir a Clase, Realizar Complementarias y Tareas y Leer el Libro Guía}\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "Los retornos inmediatos están dados por la tabla 2. En este caso, agregaremos penalizaciones para los retornos infactibles. \n",
    "\n",
    "$\n",
    "r(i|a) = \n",
    "\\begin{array}{|c|c|c|c|}\n",
    "\\hline\n",
    "\\text{Categoría/Acción}& \\text{1} & \\text{2} & \\text{3} \\\\\n",
    "\\hline\n",
    "\\text{E} & -1000 & 3 & 0 \\\\\n",
    "\\text{B} & 4 & 2 & -10 \\\\\n",
    "\\text{P} & 3 & -5 & -10 \\\\\n",
    "\\text{R} & -3 & -15 & -1000\\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "Las probabilidades de transición serán:\n",
    "\n",
    "$\n",
    "P_{i \\to j} = \n",
    "\\begin{array}{c|cccc}\n",
    "\\text{a = 1} & \\text{Excelente} & \\text{Bueno} & \\text{Regular} & \\text{Promedio} \\\\\n",
    "\\hline\n",
    "\\text{Excelente} & 0 & 0 & 0 & 0 \\\\\n",
    "\\text{Bueno} & 0.05 & 0.7 & 0.15 & 0.1 \\\\\n",
    "\\text{Promedio} & 0 & 0.2 & 0.5 & 0.3\\\\\n",
    "\\text{Regular} & 0 & 0 & 0.1 & 0.9 \\\\\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "$\n",
    "P_{i \\to j}= \n",
    "\\begin{array}{c|cccc}\n",
    "\\text{a = 2}& \\text{Excelente} & \\text{Bueno} & \\text{Regular} & \\text{Promedio} \\\\\n",
    "\\hline\n",
    "\\text{Excelente} & 0.6 & 0.4 & 0 & 0 \\\\\n",
    "\\text{Bueno} & 0.25 & 0.6 & 0.1 & 0.05 \\\\\n",
    "\\text{Promedio} & 0.1 & 0.3 & 0.5 & 0.1\\\\\n",
    "\\text{Regular} & 0 & 0.05 & 0.25 & 0.7 \\\\\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "$\n",
    "P_{i \\to j}= \n",
    "\\begin{array}{c|cccc}\n",
    "\\text{a = 3}& \\text{Excelente} & \\text{Bueno} & \\text{Regular} & \\text{Promedio} \\\\\n",
    "\\hline\n",
    "\\text{Excelente} & 0.9 & 0.1 & 0 & 0 \\\\\n",
    "\\text{Bueno} & 0.5 & 0.5 & 0 & 0 \\\\\n",
    "\\text{Promedio} & 0.2 & 0.3 & 0.5 & 0\\\\\n",
    "\\text{Regular} & 0 & 0 & 0 & 0 \\\\\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "Así, estamos listos para implementar.\n",
    "</details>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universidad de los Andes | Vigilada Mineducación. Reconocimiento como Universidad: Decreto 1297 del 30 de mayo de 1964. Reconocimiento personería jurídica: Resolución 28 del 23 de febrero de 1949 Minjusticia. Departamento de Ingeniería Industrial Carrera 1 Este No. 19 A 40 Bogotá, Colombia Tel. (57.1) 3324320 | (57.1) 3394949 Ext. 2880 /2881 http://industrial.uniandes.edu.co"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
