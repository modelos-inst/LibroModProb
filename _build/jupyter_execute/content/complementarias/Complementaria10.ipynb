{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <h3 style=\"color: #ADD8E6;\">Complementaria 10: MDP en Python</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este tutorial nos concentramos en la implementaci贸n del mod煤lo de MDP de `jmarkov` en Python. Este mod煤lo permite encontrar la pol铆tica 贸ptima de un proceso de decisi贸n markoviano (MDP) mediante dos posibles met贸dos de soluci贸n, iteraci贸n por valor o iteraci贸n de pol铆tica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #ADD8E6;\">Ejercicio MDP: h茅roes y villanos</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se abordar谩 el problema 1 del archivo Complementaria 11(Q).pdf que se encuentra en BloqueNe贸n. Modelaremos la situaci贸n como un proceso de decisi贸n markoviano (MDP). Para esto, se deben definir los seis componentes principales del problema: \n",
    "1. pocas de decisi贸n.\n",
    "2. Variable de estado.\n",
    "3. Espacio de estados.\n",
    "4. Espacio  decisiones.\n",
    "5. Probabilidades de transici贸n,\n",
    "6. Recompensas inmediatas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos las 茅pocas:\n",
    "\n",
    "$$\n",
    "E = \\{1, 2, \\dots, \\infty\\} \\rightarrow \\text{cada ataque}\n",
    "$$\n",
    "\n",
    "Definimos la variable de estado como:\n",
    "\n",
    "$$\n",
    "X_t = \\text{Lugar donde atacaron los villanos en el } (t-1)\\text{-茅simo ataque}\n",
    "$$\n",
    "\n",
    "Definimos el espacio de estados:\n",
    "\n",
    "$$\n",
    "S_X = \\{AC, AS\\}\n",
    "$$\n",
    "\n",
    "Donde $AC$ significa que atacaron el centro y $AS$ que atacaron los suburbios.\n",
    "\n",
    "El espacio de decisiones:\n",
    "\n",
    "$$\n",
    "A(i) = \\{C, S\\}\n",
    "$$\n",
    "\n",
    "Donde $C$ indica que los superh茅roes se van al centro y $S$ que se van a los suburbios.\n",
    "\n",
    "Tendremos una matriz de transici贸n para cada decisi贸n:\n",
    "\n",
    "$$\n",
    "P_{i \\to j}^{(a = \\text{Suburbio})} =\n",
    "\\begin{array}{c|cc}\n",
    "   & \\text{Centro} & \\text{Suburbio} \\\\\n",
    "   \\hline\n",
    "   \\text{Centro} & 0.5 & 0.5 \\\\\n",
    "   \\text{Suburbio} & 0.6 & 0.4\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P_{i \\to j}^{(a = \\text{Centro})} =\n",
    "\\begin{array}{c|cc}\n",
    "   & \\text{Centro} & \\text{Suburbio} \\\\\n",
    "   \\hline\n",
    "   \\text{Centro} & 0.3 & 0.7 \\\\\n",
    "   \\text{Suburbio} & 0.8 & 0.2\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Finalmente, definimos los retornos. Estos corresponden a las batallas ganadas.  \n",
    "Notemos que se ganan las batallas cuando los villanos van al lugar que los superh茅roes decidieron ir.  \n",
    "As铆, los retornos son:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "r_{(AS,S)} &= 0.4 \\\\\n",
    "r_{(AS,C)} &= 0.8 \\\\\n",
    "r_{(AC,C)} &= 0.3 \\\\\n",
    "r_{(AC,S)} &= 0.5\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para empezar con la implementaci贸n, llamamos las librer铆as necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from jmarkov.mdp.dtmdp import dtmdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos el espacio de estados en Python como un arreglo de numpy, de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Centro', 'Suburbio'], dtype='<U8')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estadosHeroes = np.array(['Centro','Suburbio'])\n",
    "estadosHeroes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el espacio de acciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ir al Centro', 'Ir al Suburbio'], dtype='<U14')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accionesHeroes = np.array(['Ir al Centro','Ir al Suburbio'])\n",
    "accionesHeroes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos las matrices de transici贸n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ir al Centro': array([[0.5, 0.5],\n",
       "        [0.6, 0.4]]),\n",
       " 'Ir al Suburbio': array([[0.3, 0.7],\n",
       "        [0.8, 0.2]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matricesHeroes = {}\n",
    "\n",
    "for a in accionesHeroes:\n",
    "    if a == 'Ir al Centro':\n",
    "        matricesHeroes[a] = np.array([[0.5,0.5],\n",
    "                                    [0.6,0.4]])\n",
    "    elif a == 'Ir al Suburbio':\n",
    "        matricesHeroes[a] = np.array([[0.3,0.7],\n",
    "                                    [0.8,0.2]])\n",
    "\n",
    "matricesHeroes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos los retornos inmediatos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3, 0.5],\n",
       "       [0.8, 0.4]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retornosHeroes = np.array([[0.3,0.5],\n",
    "                           [0.8,0.4]])\n",
    "retornosHeroes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el problema como un MDP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdpHeroes = dtmdp(estadosHeroes, accionesHeroes, matricesHeroes, retornosHeroes, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, solucionamos.\n",
    "\n",
    "El m茅todo `solve` de la librer铆a recibe por par谩metro: la tolerancia (GAP) de convergencia y el m茅todo de soluci贸n, que puede ser iteraci贸n por pol铆tica o iteraci贸n por valor. Ambos m茅todos garantizan encontrar la soluci贸n 贸ptima y llegar al mismo valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdpHeroes.solve(0, method='policy_iteration')\n",
    "value_functions, optimal_policy = mdpHeroes.solve(0, method='policy_iteration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que el m茅todo `solve` nos devuelve dos resultados. El primero se refiere al valor que toma cada una de las funciones de valor; y el segundo corresponde a la pol铆tica 贸ptima. En este caso, siempre que se est茅 en el centro se debe decidir ir al suburbio y siempre que se est茅 en el suburbio se debe decidir ir al centro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Centro': 'Ir al Suburbio', 'Suburbio': 'Ir al Centro'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.61538456433202"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valor esperado de la pol铆tica 贸ptima\n",
    "mdpHeroes.expected_policy_value(value_functions,optimal_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente, la librer铆a nos permite conocer con un comando el valor esperado de la pol铆tica 贸ptima en el largo plazo y la matriz de probabilidades de transici贸n de la pol铆tica 贸ptima. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3, 0.7],\n",
       "       [0.6, 0.4]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matriz de transici贸n de la pol铆tica 贸ptima\n",
    "mdpHeroes.policy_transition_matrix(optimal_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #4CAF50; background-color: #f9f9f9; padding: 10px; border-radius: 5px; font-size: 16px;\">\n",
    " <strong>Reto:</strong> Investiga como funciona la iteraci贸n por pol铆tica y la iteraci贸n por valor. 驴En qu茅 se parecen? 驴En qu茅 se diferencian?\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #ADD8E6;\">Ejercicio MDP: estudiantes de la Universidad de Los Alpes</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora intentemos modelar el segundo ejercicio propuesto. 驴Cu谩les ser铆an los componentes? 驴Cu谩ntas matrices de probabilidades de transici贸n tendr铆amos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resuelva el segundo ejercicio propuesto en el archivo Complementaria 11 (Q) que se encuentra en BloqueNe贸n.\n",
    "\n",
    "<details>\n",
    "<summary>Clic aqu铆 para ver la soluci贸n</summary>\n",
    "Podemos modelar el problema como un proceso de decisi贸n en el tiempo con 茅pocas infinitas.  \n",
    "As铆, el conjunto de las 茅pocas est谩 dado por:\n",
    "\n",
    "$$\n",
    "E = \\{1,2,\\dots,\\infty\\} \\rightarrow \\text{cada semestre}\n",
    "$$\n",
    "\n",
    "La variable de estados ser谩 \n",
    "$$\n",
    "X_{t} = \\text{Clasificaci贸n de un estudiante en la 茅poca } t\n",
    "$$\n",
    "Su respectivo espacio de estados:\n",
    "$$\n",
    "S_{X} = \\{ Excelente, Bueno, Promedio, Regular\\}\n",
    "$$\n",
    "Ya que un estudiante podr谩 decidir si asistir a clase (1), asistir a clase y realizar complementarias y tareas (2) y asistir a clase, realizar complementarias y tareas y leer el libro gu铆a (3). \n",
    "$$\n",
    "A(i) = \n",
    "\\begin{cases}\n",
    "&\\text{Asistir a Clase (1)}, \\\\\n",
    "&\\text{Asistir a Clase y Realizar Complementarias y Tareas (2)}, \\\\\n",
    "&\\text{Asistir a Clase, Realizar Complementarias y Tareas y Leer el Libro Gu铆a}\n",
    "\\end{cases}\n",
    "$$\n",
    "Los retornos inmediatos est谩n dados por la tabla 2. En este caso, agregaremos penalizaciones para los retornos inexistentes. \n",
    "$$\n",
    "r(i|a) = \n",
    "\\begin{array}{|c|c|c|c|}\n",
    "\\hline\n",
    "\\text{Categor铆a/Acci贸n}& \\text{1} & \\text{2} & \\text{3} \\\\\n",
    "\\hline\n",
    "\\text{E} & -1000 & 3 & 0 \\\\\n",
    "\\text{B} & 4 & 2 & -10 \\\\\n",
    "\\text{P} & 3 & -5 & -10 \\\\\n",
    "\\text{R} & -3 & -15 & -1000\\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "Las probabilidades de transici贸n ser谩n:\n",
    "\n",
    "$$\n",
    "P_{i \\to j} = \n",
    "\\begin{array}{c|cccc}\n",
    "\\text{a = 1} & \\text{Excelente} & \\text{Bueno} & \\text{Promedio} & \\text{Regular} \\\\\n",
    "\\hline\n",
    "\\text{Excelente} & 1 & 0 & 0 & 0 \\\\\n",
    "\\text{Bueno} & 0.05 & 0.7 & 0.15 & 0.1 \\\\\n",
    "\\text{Promedio} & 0 & 0.2 & 0.5 & 0.3\\\\\n",
    "\\text{Regular} & 0 & 0 & 0.1 & 0.9 \\\\\n",
    "\\end{array}\n",
    "\n",
    "\\\\\n",
    "\n",
    "P_{i \\to j}= \n",
    "\\begin{array}{c|cccc}\n",
    "\\text{a = 2}& \\text{Excelente} & \\text{Bueno} & \\text{Promedio} & \\text{RegularPromedio} \\\\\n",
    "\\hline\n",
    "\\text{Excelente} & 0.6 & 0.4 & 0 & 0 \\\\\n",
    "\\text{Bueno} & 0.25 & 0.6 & 0.1 & 0.05 \\\\\n",
    "\\text{Promedio} & 0.1 & 0.3 & 0.5 & 0.1\\\\\n",
    "\\text{Regular} & 0 & 0.05 & 0.25 & 0.7 \\\\\n",
    "\\end{array}\n",
    "\\\\\n",
    "\n",
    "P_{i \\to j}= \n",
    "\\begin{array}{c|cccc}\n",
    "\\text{a = 3}& \\text{Excelente} & \\text{Bueno} & \\text{Promedio} & \\text{Regular} \\\\\n",
    "\\hline\n",
    "\\text{Excelente} & 0.9 & 0.1 & 0 & 0 \\\\\n",
    "\\text{Bueno} & 0.5 & 0.5 & 0 & 0 \\\\\n",
    "\\text{Promedio} & 0.2 & 0.3 & 0.5 & 0\\\\\n",
    "\\text{Regular} & 0 & 0 & 0 & 1 \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "As铆, estamos listos para implementar.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universidad de los Andes | Vigilada Mineducaci贸n. Reconocimiento como Universidad: Decreto 1297 del 30 de mayo de 1964. Reconocimiento personer铆a jur铆dica: Resoluci贸n 28 del 23 de febrero de 1949 Minjusticia. Departamento de Ingenier铆a Industrial Carrera 1 Este No. 19 A 40 Bogot谩, Colombia Tel. (57.1) 3324320 | (57.1) 3394949 Ext. 2880 /2881 http://industrial.uniandes.edu.co"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}